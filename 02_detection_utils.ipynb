{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp detection.utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detection.utils\n",
    "\n",
    "> utilities for detection pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### taken from [here]() with some methods heavily modified in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "\n",
    "        return self.label\n",
    "\n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "\n",
    "        return self.score\n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def decode_netout(netout, anchors, obj_thresh, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "    boxes = []\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            if(objectness.all() <= obj_thresh): continue\n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    new_w, new_h = net_w, net_h\n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    intersect = intersect_w * intersect_h\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    return float(intersect) / union\n",
    "\n",
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "\n",
    "# load and prepare an image\n",
    "def load_image_pixels(img_path, shape):\n",
    "    # load the image to get its shape\n",
    "    image = load_img(img_path)\n",
    "    width, height = image.size\n",
    "    # load the image with the required size\n",
    "    image = load_img(img_path, target_size=shape)\n",
    "    # convert to numpy array\n",
    "    image = img_to_array(image)\n",
    "    # scale pixel values to [0, 1]\n",
    "    image = image.astype('float32')\n",
    "    image /= 255.0\n",
    "    # add a dimension so that we have one sample\n",
    "    image = expand_dims(image, 0)\n",
    "    return image, width, height\n",
    "\n",
    "# get all of the results above a threshold\n",
    "def get_boxes(boxes, labels, thresh):\n",
    "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
    "    # enumerate all boxes\n",
    "    for box in boxes:\n",
    "        # enumerate all possible labels\n",
    "        for i in range(len(labels)):\n",
    "            # check if the threshold for this label is high enough\n",
    "            if box.classes[i] > thresh:\n",
    "                v_boxes.append(box)\n",
    "                v_labels.append(labels[i])\n",
    "                v_scores.append(box.classes[i]*100)\n",
    "                # don't break, many labels may trigger for one box\n",
    "    return v_boxes, v_labels, v_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generates boxes, and alphabet label if classifier is specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_boxes(image,\n",
    "                   v_boxes,\n",
    "                   v_labels,\n",
    "                   v_scores,\n",
    "                   figsize,\n",
    "                   save_dir,\n",
    "                   classifier):\n",
    "    coordinates, labels, hands, heatmaps, overlays = [], [], [], [], []\n",
    "    for i in range(len(v_boxes)):\n",
    "        box = v_boxes[i]\n",
    "        # get coordinates\n",
    "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
    "        # calculate width and height of the box\n",
    "        width, height = x2 - x1, y2 - y1\n",
    "        coordinates.append([x1, y1, width, height])\n",
    "\n",
    "        if not classifier:\n",
    "            # draw text and score in top left corner\n",
    "            label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
    "            labels.append(label)\n",
    "        else:\n",
    "            hand = cv2.resize(image[y1:y2+1, x1:x2+1], (224, 224))\n",
    "            hand = hand/255.\n",
    "            hand = hand.reshape(1, 224, 224, 3)\n",
    "            hands.append(hand)\n",
    "\n",
    "            model = classification.Classifier()\n",
    "            model.classifier = classifier\n",
    "            model.feature_extractor = MobileNet(input_shape = (224, 224, 3), include_top=True,weights ='imagenet')\n",
    "            output = model.feature_extractor.layers[-6].output\n",
    "            model.feature_extractor = tf.keras.Model(model.feature_extractor.inputs, output)\n",
    "            heatmap_result = model.generate_heat_map(hand)\n",
    "\n",
    "            # draw text and score in top left corner\n",
    "            label = \"%s (%.3f)\" % (heatmap_result['label'], v_scores[i])\n",
    "            labels.append(label)\n",
    "            heatmaps.append(heatmap_result['heatmap'])\n",
    "            overlays.append(heatmap_result['overlay'])\n",
    "    results = {'coordinates': coordinates, 'labels': labels, 'hands': hands, 'heatmaps': heatmaps, 'overlays': overlays}\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### draws the above results and saves if specfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _draw_boxes(img_path,\n",
    "                v_boxes,\n",
    "                v_labels,\n",
    "                v_scores,\n",
    "                figsize,\n",
    "                save_dir,\n",
    "                classifier,\n",
    "                show_classes):\n",
    "    if show_classes and classifier == None:\n",
    "        print('No classifer, cannot display classes')\n",
    "        raise\n",
    "    # load the image\n",
    "    image = plt.imread(img_path)\n",
    "\n",
    "    results = generate_boxes(image,\n",
    "                             v_boxes,\n",
    "                             v_labels,\n",
    "                             v_scores,\n",
    "                             figsize,\n",
    "                             save_dir,\n",
    "                             classifier)\n",
    "\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    if not show_classes:\n",
    "        plt.imshow(image)\n",
    "        # get the context for drawing boxes\n",
    "        ax = plt.gca()\n",
    "\n",
    "        for i, label in enumerate(results['labels']):\n",
    "            x1, y1, width, height = results['coordinates'][i]\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "            plt.text(x1-10, y1-10, label, color='white', fontsize=20)\n",
    "    else:\n",
    "        gridspec.GridSpec(4, 5)\n",
    "\n",
    "        plt.subplot2grid((4, 5), (0, 0), colspan=5, rowspan=2)\n",
    "        ax = plt.gca()\n",
    "        plt.imshow(image)\n",
    "        for i, label in enumerate(results['labels']):\n",
    "            x1, y1, width, height = results['coordinates'][i]\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "            plt.text(x1-10, y1-10, label, color='white', fontsize=20)\n",
    "        for i, hand in enumerate(results['hands']):\n",
    "            plt.subplot2grid((4, 5), (i+2, 1))\n",
    "            plt.imshow(hand.reshape(224, 224, 3))\n",
    "            plt.title(results['labels'][i])\n",
    "\n",
    "            plt.subplot2grid((4, 5), (i+2, 2))\n",
    "            plt.title('heatmap')\n",
    "            plt.imshow(results['heatmaps'][i].reshape(224, 224, 3))\n",
    "\n",
    "            plt.subplot2grid((4, 5), (i+2, 3))\n",
    "            plt.title('overlay')\n",
    "            plt.imshow(results['overlays'][i].reshape(224, 224, 3))\n",
    "\n",
    "    # show the plot\n",
    "    f.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    if save_dir:\n",
    "        visualization.save(save_dir, 'detection', fig=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### wrapper that passes intermediate results into aforementioned methods and draws the boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def draw_boxes(hand_detector,\n",
    "               img_paths,\n",
    "               save_dir=None,\n",
    "               classifier=None,\n",
    "               show_classes=False,\n",
    "               class_threshold=.6,\n",
    "               nms_thresh=.6,\n",
    "               figsize=(10, 10)):\n",
    "    # define the expected input shape for the model\n",
    "    input_w, input_h = 416, 416\n",
    "    # define the anchors\n",
    "    anchors = [[116,90, 156,198, 373,326], [30,61, 62,45, 59,119], [10,13, 16,30, 33,23]]\n",
    "\n",
    "    for img_path in img_paths:\n",
    "        # load and prepare image\n",
    "        image, image_w, image_h = load_image_pixels(img_path, (input_w, input_h))\n",
    "\n",
    "        yhat = hand_detector.predict(image)\n",
    "\n",
    "        # define the probability threshold for detected objects\n",
    "        boxes = list()\n",
    "        for i in range(len(yhat)):\n",
    "            # decode the output of the network\n",
    "            boxes += decode_netout(yhat[i][0], anchors[i], class_threshold, input_h, input_w)\n",
    "        # correct the sizes of the bounding boxes for the shape of the image\n",
    "        correct_yolo_boxes(boxes, image_h, image_w, input_h, input_w)\n",
    "        # suppress non-maximal boxes\n",
    "        do_nms(boxes, nms_thresh)\n",
    "        # define the labels\n",
    "        labels = ['hand']\n",
    "        # get the details of the detected objects\n",
    "        v_boxes, v_labels, v_scores = get_boxes(boxes, labels, class_threshold)\n",
    "        _draw_boxes(img_path,\n",
    "                    v_boxes,\n",
    "                    v_labels,\n",
    "                    v_scores,\n",
    "                    figsize,\n",
    "                    save_dir,\n",
    "                    classifier=classifier,\n",
    "                    show_classes=show_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper method for loading detection and classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def load_model(path, weights=False):\n",
    "    print('loading model...\\r', end='')\n",
    "    if weights:\n",
    "        model = yolov3.make_yolov3_model()\n",
    "        weight_reader = yolov3.WeightReader(path)\n",
    "        weight_reader.load_weights(model)\n",
    "    else:\n",
    "        model = tf.keras.models.load_model(path)\n",
    "    print('model loaded!')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
